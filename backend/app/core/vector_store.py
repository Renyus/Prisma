import logging
import httpx
import asyncio
import threading
import time
from typing import List, Dict, Any, Optional
import chromadb
from chromadb.config import Settings as ChromaSettings
from app.core.config import settings

# --- å¼ºåˆ¶é…ç½®æ—¥å¿—æ ¼å¼ï¼Œç¡®ä¿æ‚¨èƒ½çœ‹åˆ°è¾“å‡º ---
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)
# ----------------------------------------

class VectorStore:
    _instance = None

    def __new__(cls):
        if cls._instance is None:
            cls._instance = super(VectorStore, cls).__new__(cls)
            cls._instance.initialized = False
        return cls._instance

    def __init__(self):
        if self.initialized:
            return
            
        self.initialized = True
        self.client = None
        self.collection = None
        
        # æŒä¹…åŒ–ä¼˜åŒ–ç›¸å…³
        self._sync_lock = threading.Lock()
        self._pending_operations = []
        self._sync_timer = None
        self._sync_interval = 30  # 30ç§’åŒæ­¥ä¸€æ¬¡
        self._last_sync_time = time.time()
        
        key, url = settings.RAG_CREDENTIALS
        self.api_key = key
        self.api_url = url.rstrip('/')
        if not self.api_url.endswith("/embeddings"):
             self.api_url += "/embeddings"
        
        if key:
            self._init_chroma()
            self._start_sync_timer()
        else:
            logger.warning("âš ï¸ æœªé…ç½® RAG API Keyï¼Œå‘é‡æ•°æ®åº“ä¸å¯ç”¨ã€‚")

    def _init_chroma(self):
        try:
            logger.info(f"ğŸ“‚ åˆå§‹åŒ– ChromaDB: {settings.RAG_VECTOR_DB_PATH}")
            self.client = chromadb.PersistentClient(
                path=settings.RAG_VECTOR_DB_PATH,
                settings=ChromaSettings(anonymized_telemetry=False)
            )
            
            self.collection = self.client.get_or_create_collection(
                name="sakura_memories",
                metadata={"hnsw:space": "cosine"}
            )
            logger.info("âœ… ChromaDB å°±ç»ªã€‚")
            
        except Exception as e:
            logger.error(f"âŒ ChromaDB åˆå§‹åŒ–å¤±è´¥: {e}")
            self.client = None

    def _start_sync_timer(self):
        """å¯åŠ¨å®šæ—¶åŒæ­¥æœºåˆ¶"""
        def sync_worker():
            while True:
                try:
                    time.sleep(self._sync_interval)
                    self._force_sync()
                except Exception as e:
                    logger.error(f"å®šæ—¶åŒæ­¥å‡ºé”™: {e}")
        
        sync_thread = threading.Thread(target=sync_worker, daemon=True)
        sync_thread.start()
        logger.info(f"ğŸ”„ å¯åŠ¨å®šæ—¶åŒæ­¥æœºåˆ¶ï¼Œé—´éš”: {self._sync_interval}ç§’")

    def _force_sync(self):
        """å¼ºåˆ¶åŒæ­¥æ‰€æœ‰å¾…å¤„ç†çš„æ“ä½œ"""
        with self._sync_lock:
            if not self._pending_operations:
                return
            
            try:
                # è§¦å‘ChromaDBçš„å†…éƒ¨åŒæ­¥
                if hasattr(self.client, '_db'):
                    self.client._db.flush()
                
                # è®°å½•åŒæ­¥ç»Ÿè®¡
                op_count = len(self._pending_operations)
                self._pending_operations.clear()
                self._last_sync_time = time.time()
                
                logger.info(f"ğŸ’¾ [Sync] å·²åŒæ­¥ {op_count} ä¸ªæ“ä½œï¼Œè€—æ—¶: {time.time() - self._last_sync_time:.2f}ç§’")
                
            except Exception as e:
                logger.error(f"å¼ºåˆ¶åŒæ­¥å¤±è´¥: {e}")

    def _queue_operation(self, operation_type: str, **kwargs):
        """å°†æ“ä½œåŠ å…¥å¾…å¤„ç†é˜Ÿåˆ—"""
        with self._sync_lock:
            self._pending_operations.append({
                'type': operation_type,
                'timestamp': time.time(),
                **kwargs
            })

    def is_available(self) -> bool:
        return self.collection is not None

    async def get_embeddings(self, texts: List[str]) -> List[List[float]]:
        """
        [Async] æ˜¾å¼è°ƒç”¨ API è·å–å‘é‡
        """
        if not texts:
            return []
            
        # [INFO] å¼ºåˆ¶æ˜¾ç¤º
        preview = texts[0][:30] + "..." if len(texts[0]) > 30 else texts[0]
        logger.info(f"ğŸ” [Embeddingè¯·æ±‚] æ–‡æœ¬æ•°: {len(texts)} | ç¤ºä¾‹: '{preview}'")
            
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        
        payload = {
            "input": texts,
            "model": settings.RAG_EMBEDDING_MODEL,
            "encoding_format": "float"
        }

        try:
            async with httpx.AsyncClient(timeout=30.0) as client:
                response = await client.post(
                    self.api_url, 
                    headers=headers, 
                    json=payload
                )
                response.raise_for_status()
                data = response.json()
                
                sorted_data = sorted(data["data"], key=lambda x: x["index"])
                embeddings = [item["embedding"] for item in sorted_data]
                
                # [INFO] å¼ºåˆ¶æ˜¾ç¤º
                logger.info(f"âœ… [EmbeddingæˆåŠŸ] è·å–åˆ° {len(embeddings)} æ¡å‘é‡")
                return embeddings
                
        except Exception as e:
            logger.error(f"âŒ Embedding API å¤±è´¥: {e}")
            raise e

    async def add_memory(self, memory_id: str, text: str, metadata: Dict[str, Any]):
        if not self.is_available():
            return

        try:
            embeddings = await self.get_embeddings([text])
            if not embeddings:
                return

            # ä½¿ç”¨æ‰¹é‡æ“ä½œå‡å°‘ç¢ç‰‡
            self.collection.add(
                embeddings=embeddings,
                documents=[text],
                metadatas=[metadata],
                ids=[memory_id]
            )
            
            # è®°å½•æ“ä½œåˆ°é˜Ÿåˆ—
            self._queue_operation('add_memory', memory_id=memory_id)
            logger.info(f"ğŸ’¾ [Vectorå†™å…¥] å·²å­˜å‚¨è®°å¿† ID={memory_id}")
            
        except Exception as e:
            logger.error(f"âŒ å†™å…¥å‘é‡åº“å¤±è´¥: {e}")

    async def delete_memory(self, memory_id: str):
        if not self.is_available():
            return
        try:
            self.collection.delete(ids=[memory_id])
            self._queue_operation('delete_memory', memory_id=memory_id)
            logger.info(f"ğŸ—‘ï¸ [Vectoråˆ é™¤] å·²åˆ é™¤è®°å¿† ID={memory_id}")
        except Exception as e:
            logger.error(f"âŒ åˆ é™¤å‘é‡å¤±è´¥: {e}")

    async def search(self, query: str, user_id: str, limit: int = 5) -> List[str]:
        if not self.is_available():
            logger.warning("âš ï¸ å‘é‡åº“æœªè¿æ¥ï¼Œè·³è¿‡æ£€ç´¢")
            return []

        try:
            # [INFO] å¼ºåˆ¶æ˜¾ç¤º
            logger.info(f"ğŸ” [RAGæ£€ç´¢] ç”¨æˆ·: {user_id} | Query: '{query}'")
            
            query_embeddings = await self.get_embeddings([query])
            if not query_embeddings:
                return []

            results = self.collection.query(
                query_embeddings=query_embeddings,
                n_results=limit,
                where={"user_id": user_id} 
            )
            
            found_ids = results["ids"][0] if results and results["ids"] else []
            
            if found_ids:
                logger.info(f"ğŸ§  [RAGå‘½ä¸­] æ‰¾åˆ° {len(found_ids)} æ¡ç›¸å…³å‘é‡")
            else:
                logger.info(f"ğŸ¤· [RAGè½ç©º] æœªæ‰¾åˆ°ç›¸å…³è®°å¿†")
                
            return found_ids
            
        except Exception as e:
            logger.error(f"âŒ å‘é‡æ£€ç´¢å‡ºé”™: {e}")
            return []

    # ğŸ”¥ [æ–°å¢] æ£€æŸ¥æ˜¯å¦å­˜åœ¨ç›¸ä¼¼è®°å¿†
    async def exist_similar(self, text: str, user_id: str, threshold: float = 0.25) -> bool:
        """
        æ£€æŸ¥åº“ä¸­æ˜¯å¦å·²å­˜åœ¨ç›¸ä¼¼å†…å®¹ã€‚
        :param threshold: è·ç¦»é˜ˆå€¼ (Cosine Distance). è¶Šå°è¶Šç›¸ä¼¼. 0.25 å¤§çº¦å¯¹åº” 0.75 çš„ç›¸ä¼¼åº¦ã€‚
        :return: True è¡¨ç¤ºå·²å­˜åœ¨(é‡å¤)ï¼ŒFalse è¡¨ç¤ºæ˜¯æ–°çš„
        """
        if not self.is_available(): return False
        try:
            query_embeddings = await self.get_embeddings([text])
            if not query_embeddings: return False

            # æ£€ç´¢æœ€è¿‘çš„ 1 æ¡
            results = self.collection.query(
                query_embeddings=query_embeddings,
                n_results=1,
                where={"user_id": user_id}
            )

            # æ£€æŸ¥è·ç¦»
            if results and results['distances'] and results['distances'][0]:
                dist = results['distances'][0][0]
                # debug log
                # logger.info(f"ğŸ” [æŸ¥é‡] '{text[:10]}...' æœ€å°è·ç¦»: {dist:.4f} (é˜ˆå€¼: {threshold})")
                if dist < threshold:
                    return True # è·ç¦»å¾ˆå°ï¼Œè¯´æ˜å·²å­˜åœ¨ç›¸ä¼¼è®°å¿†
            
            return False
        except Exception as e:
            logger.error(f"æŸ¥é‡å¤±è´¥: {e}")
            return False

    # --- Lorebook ä¸“ç”¨æ–¹æ³• ---

    async def upsert_lore(self, entry_id: str, text: str, lorebook_id: str, tags: List[str] = None):
        """æ’å…¥æˆ–æ›´æ–°ä¸–ç•Œä¹¦æ¡ç›®"""
        if not self.is_available(): return
        if not text: return

        try:
            embeddings = await self.get_embeddings([text])
            if not embeddings: return

            metadata = {
                "type": "lore", 
                "lorebook_id": lorebook_id,
                "tags": ",".join(tags) if tags else ""
            }

            self.collection.add(
                embeddings=embeddings,
                documents=[text],
                metadatas=[metadata],
                ids=[entry_id]
            )
            
            self._queue_operation('upsert_lore', entry_id=entry_id)
            logger.info(f"ğŸ“˜ [Vector] Upsert Lore ID={entry_id}")
        except Exception as e:
            logger.error(f"Lore upsert å¤±è´¥: {e}")

    async def delete_lore(self, entry_id: str):
        """åˆ é™¤ä¸–ç•Œä¹¦æ¡ç›®"""
        if not self.is_available(): return
        try:
            self.collection.delete(ids=[entry_id])
            self._queue_operation('delete_lore', entry_id=entry_id)
            logger.info(f"ğŸ—‘ï¸ [Vector] Delete Lore ID={entry_id}")
        except Exception as e:
            logger.error(f"Lore delete å¤±è´¥: {e}")

    async def search_lore(self, query: str, active_book_ids: List[str], limit: int = 5, all_entries: List[Dict] = None) -> List[Dict]:
        """
        åœ¨æŒ‡å®šçš„ active_book_ids èŒƒå›´å†…æœç´¢ç›¸å…³æ¡ç›®
        è¿”å›å®Œæ•´çš„æ¡ç›®å¯¹è±¡åˆ—è¡¨ï¼Œè€Œä¸æ˜¯ä»…ID
        """
        if not self.is_available() or not active_book_ids:
            return []
        
        try:
            query_embeddings = await self.get_embeddings([query])
            if not query_embeddings: return []

            # Chroma $in æŸ¥è¯¢
            where_filter = {
                "$and": [
                    {"type": "lore"},
                    {"lorebook_id": {"$in": active_book_ids}}
                ]
            }

            results = self.collection.query(
                query_embeddings=query_embeddings,
                n_results=limit,
                where=where_filter
            )
            
            found_ids = results["ids"][0] if results and results["ids"] else []
            if not found_ids:
                return []
            
            logger.info(f"ğŸ“˜ [Loreæ£€ç´¢] å‘é‡å‘½ä¸­ {len(found_ids)} æ¡ (Query: {query[:10]}...)")
            
            # å¦‚æœæä¾›äº†all_entriesï¼Œç›´æ¥ä»å…¶ä¸­åŒ¹é…è¿”å›å®Œæ•´å¯¹è±¡
            if all_entries:
                matched_entries = []
                found_ids_set = set(found_ids)
                for entry in all_entries:
                    if str(entry.get("id")) in found_ids_set:
                        matched_entries.append(entry)
                return matched_entries
            
            # å¦åˆ™åªè¿”å›IDåˆ—è¡¨ï¼ˆå‘åå…¼å®¹ï¼‰
            return found_ids

        except Exception as e:
            logger.error(f"Lore search å¤±è´¥: {e}")
            return []

    # ğŸ”¥ [æ–°å¢] æ‰‹åŠ¨è§¦å‘åŒæ­¥
    async def manual_sync(self):
        """æ‰‹åŠ¨è§¦å‘åŒæ­¥æ“ä½œ"""
        logger.info("ğŸ”„ æ‰‹åŠ¨è§¦å‘åŒæ­¥æ“ä½œ")
        self._force_sync()

    # ğŸ”¥ [æ–°å¢] è·å–åŒæ­¥çŠ¶æ€
    def get_sync_status(self) -> Dict[str, Any]:
        """è·å–å½“å‰åŒæ­¥çŠ¶æ€"""
        with self._sync_lock:
            return {
                'pending_operations': len(self._pending_operations),
                'last_sync_time': self._last_sync_time,
                'sync_interval': self._sync_interval,
                'next_sync_in': max(0, self._sync_interval - (time.time() - self._last_sync_time))
            }

    # ğŸ”¥ [æ–°å¢] ä¼˜é›…å…³é—­
    def shutdown(self):
        """ä¼˜é›…å…³é—­ï¼Œç¡®ä¿æ•°æ®åŒæ­¥"""
        logger.info("ğŸ”„ æ­£åœ¨å…³é—­VectorStoreï¼Œæ‰§è¡Œæœ€ç»ˆåŒæ­¥...")
        self._force_sync()
        logger.info("âœ… VectorStoreå·²å®‰å…¨å…³é—­")

vector_store = VectorStore()
